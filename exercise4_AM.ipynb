{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "This week we are going to use a new data set which contains 1070 purchases where the customer either purchased Citrus Hill or Minute Maid Orange Juice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Purchase</th>\n",
       "      <th>WeekofPurchase</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>PriceCH</th>\n",
       "      <th>PriceMM</th>\n",
       "      <th>DiscCH</th>\n",
       "      <th>DiscMM</th>\n",
       "      <th>SpecialCH</th>\n",
       "      <th>SpecialMM</th>\n",
       "      <th>LoyalCH</th>\n",
       "      <th>SalePriceMM</th>\n",
       "      <th>SalePriceCH</th>\n",
       "      <th>PriceDiff</th>\n",
       "      <th>Store7</th>\n",
       "      <th>PctDiscMM</th>\n",
       "      <th>PctDiscCH</th>\n",
       "      <th>ListPriceDiff</th>\n",
       "      <th>STORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091398</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>7</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956535</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Purchase  WeekofPurchase  StoreID  PriceCH  PriceMM  DiscCH  DiscMM  \\\n",
       "0         0             237        1     1.75     1.99    0.00     0.0   \n",
       "1         0             239        1     1.75     1.99    0.00     0.3   \n",
       "2         0             245        1     1.86     2.09    0.17     0.0   \n",
       "3         1             227        1     1.69     1.69    0.00     0.0   \n",
       "4         0             228        7     1.69     1.69    0.00     0.0   \n",
       "\n",
       "   SpecialCH  SpecialMM   LoyalCH  SalePriceMM  SalePriceCH  PriceDiff  \\\n",
       "0          0          0  0.500000         1.99         1.75       0.24   \n",
       "1          0          1  0.600000         1.69         1.75      -0.06   \n",
       "2          0          0  0.680000         2.09         1.69       0.40   \n",
       "3          0          0  0.400000         1.69         1.69       0.00   \n",
       "4          0          0  0.956535         1.69         1.69       0.00   \n",
       "\n",
       "   Store7  PctDiscMM  PctDiscCH  ListPriceDiff  STORE  \n",
       "0       0   0.000000   0.000000           0.24      1  \n",
       "1       0   0.150754   0.000000           0.24      1  \n",
       "2       0   0.000000   0.091398           0.23      1  \n",
       "3       0   0.000000   0.000000           0.00      1  \n",
       "4       1   0.000000   0.000000           0.00      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "oj = pd.read_csv('data/OJ.csv')\n",
    "oj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.cross_validation as cv\n",
    "X = oj.iloc[:, 1:] \n",
    "Y = oj.iloc[:, 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features and the target variable are already prepared for you. What you are going to do is:\n",
    "\n",
    "**1. Split**\n",
    "\n",
    "Split the data set into two parts: training set and test set(with *random_state=0*, and *test_size=1.0/2*).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (535, 17)(535,)\n",
      "Test: (535, 17)(535,)\n"
     ]
    }
   ],
   "source": [
    "### Splitting the data to see the shape\n",
    "x_train, x_test, y_train, y_test = cv.train_test_split(X, \n",
    "                                                       Y, \n",
    "                                                       test_size=1.0/2, \n",
    "                                                       random_state=0)\n",
    "#print \"Original: \" + str(spine.data.shape) + str(spine.target.shape)\n",
    "print \"Training: \" + str(x_train.shape) + str(y_train.shape)\n",
    "print \"Test: \" + str(x_test.shape) + str(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-Use SVM Default settings\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training error:', 0.22616822429906547)\n",
      "('Test error:', 0.30280373831775698)\n"
     ]
    }
   ],
   "source": [
    "print (\"Training error:\",1-svm_model.score(x_train,y_train))\n",
    "print (\"Test error:\",1-svm_model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Support vector machine**\n",
    "\n",
    "(1) Fit a svm model on the training set, report the training error and test error.(Just use the **svm.SVC** with default setting.)\n",
    "    \n",
    "(2) Change the value of parameter $C$ from $10^{-3}$ to $10^3$, make a plot to watch how the training error and test error varies. You can choose the value of $C$ from the array `np.logspace(-3, 3, 300)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60560747663551406, 0.60560747663551406, 0.64672897196261681, 0.77383177570093453, 0.84859813084112146, 0.8654205607476636, 0.87102803738317758, 0.88971962616822431, 0.89532710280373828, 0.90654205607476634, 0.90654205607476634, 0.91028037383177574, 0.9196261682242991, 0.92336448598130838, 0.93271028037383175]\n",
      "[0.61495327102803743, 0.61495327102803743, 0.63738317757009344, 0.69719626168224302, 0.77757009345794392, 0.78691588785046729, 0.79439252336448596, 0.77757009345794392, 0.77570093457943923, 0.77196261682242995, 0.7570093457943925, 0.7570093457943925, 0.7570093457943925, 0.74579439252336444, 0.74953271028037383]\n"
     ]
    }
   ],
   "source": [
    "### vary C parameter to check training & test error\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "test_coef = []\n",
    "train_coef = []\n",
    "c_100=[0.001, 0.01, 0.1,1,6.25055193e+00,   8.28642773e+00,10,4.49843267e+01,\n",
    "         5.96362332e+01,   7.90604321e+01,100,1.12883789e+02,   2.33572147e+02,\n",
    "         4.83293024e+02,1000]\n",
    "for i in c_100:\n",
    "    svm_model = svm.SVC(kernel = 'rbf', C = i, degree=3)\n",
    "    #ridge_scores =cross_val_score(ridge_est, x, y, cv = 5)\n",
    "    svm_model.fit(x_train,y_train)\n",
    "    train_error = svm_model.score(x_train,y_train)\n",
    "    #print np.sqrt(train_error)\n",
    "    test_error = svm_model.score(x_test,y_test)\n",
    "    test_coef.append(test_error)\n",
    "    train_coef.append(train_error)\n",
    "\n",
    "print train_coef\n",
    "print test_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x111000e90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTMzMrGZOJmZmVjMnEzMzq9n/B4wuVeNKUrZEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d92d190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline \n",
    "import matplotlib.pyplot as pl\n",
    "pl.plot(c_100, train_coef)\n",
    "pl.plot(c_100, test_coef, color='red')\n",
    "pl.xlabel('C parameter')\n",
    "pl.ylabel('trsining & test accuracies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Decision tree**\n",
    "\n",
    "(1) Fit a decision tree model on the training set with the default setting.\n",
    "    \n",
    "(2) Set the depth of the tree from 1 to 30. Look the varies of the training error and test error.\n",
    "    \n",
    "(3) Use the function **grid_search.GridSearchCV** to find the best parameters. What's the best parameters? What's the best score? What's the training error and test error of the best model. The possible combination of the parameters may be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99252336448598133"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing standard Decision Tree\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "tree_model.fit(x_train,y_train)\n",
    "tree_model.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.grid_search as gs\n",
    "grid_para_tree = {'criterion': ['gini', 'entropy'], 'max_depth': range(1, 31)}\n",
    "grid_search_tree = gs.GridSearchCV(tree_model, grid_para_tree, cv=5, scoring='accuracy')\n",
    "grid_search_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.74766, std: 0.03662, params: {'criterion': 'gini', 'max_depth': 1},\n",
       " mean: 0.77009, std: 0.03684, params: {'criterion': 'gini', 'max_depth': 2},\n",
       " mean: 0.81308, std: 0.02689, params: {'criterion': 'gini', 'max_depth': 3},\n",
       " mean: 0.79626, std: 0.02991, params: {'criterion': 'gini', 'max_depth': 4},\n",
       " mean: 0.77757, std: 0.04488, params: {'criterion': 'gini', 'max_depth': 5},\n",
       " mean: 0.74206, std: 0.05492, params: {'criterion': 'gini', 'max_depth': 6},\n",
       " mean: 0.77757, std: 0.03475, params: {'criterion': 'gini', 'max_depth': 7},\n",
       " mean: 0.75327, std: 0.04778, params: {'criterion': 'gini', 'max_depth': 8},\n",
       " mean: 0.75888, std: 0.04416, params: {'criterion': 'gini', 'max_depth': 9},\n",
       " mean: 0.74579, std: 0.04076, params: {'criterion': 'gini', 'max_depth': 10},\n",
       " mean: 0.74393, std: 0.05025, params: {'criterion': 'gini', 'max_depth': 11},\n",
       " mean: 0.74393, std: 0.04142, params: {'criterion': 'gini', 'max_depth': 12},\n",
       " mean: 0.73645, std: 0.04568, params: {'criterion': 'gini', 'max_depth': 13},\n",
       " mean: 0.74393, std: 0.04165, params: {'criterion': 'gini', 'max_depth': 14},\n",
       " mean: 0.74206, std: 0.03205, params: {'criterion': 'gini', 'max_depth': 15},\n",
       " mean: 0.73271, std: 0.04654, params: {'criterion': 'gini', 'max_depth': 16},\n",
       " mean: 0.73832, std: 0.05042, params: {'criterion': 'gini', 'max_depth': 17},\n",
       " mean: 0.74766, std: 0.03765, params: {'criterion': 'gini', 'max_depth': 18},\n",
       " mean: 0.73271, std: 0.04019, params: {'criterion': 'gini', 'max_depth': 19},\n",
       " mean: 0.73645, std: 0.03957, params: {'criterion': 'gini', 'max_depth': 20},\n",
       " mean: 0.74019, std: 0.04231, params: {'criterion': 'gini', 'max_depth': 21},\n",
       " mean: 0.73645, std: 0.04782, params: {'criterion': 'gini', 'max_depth': 22},\n",
       " mean: 0.73271, std: 0.04800, params: {'criterion': 'gini', 'max_depth': 23},\n",
       " mean: 0.74579, std: 0.04959, params: {'criterion': 'gini', 'max_depth': 24},\n",
       " mean: 0.74206, std: 0.04519, params: {'criterion': 'gini', 'max_depth': 25},\n",
       " mean: 0.73832, std: 0.03513, params: {'criterion': 'gini', 'max_depth': 26},\n",
       " mean: 0.73832, std: 0.04500, params: {'criterion': 'gini', 'max_depth': 27},\n",
       " mean: 0.74019, std: 0.04377, params: {'criterion': 'gini', 'max_depth': 28},\n",
       " mean: 0.73832, std: 0.04628, params: {'criterion': 'gini', 'max_depth': 29},\n",
       " mean: 0.74579, std: 0.04094, params: {'criterion': 'gini', 'max_depth': 30},\n",
       " mean: 0.72523, std: 0.02025, params: {'criterion': 'entropy', 'max_depth': 1},\n",
       " mean: 0.75701, std: 0.04296, params: {'criterion': 'entropy', 'max_depth': 2},\n",
       " mean: 0.81495, std: 0.02745, params: {'criterion': 'entropy', 'max_depth': 3},\n",
       " mean: 0.80561, std: 0.02018, params: {'criterion': 'entropy', 'max_depth': 4},\n",
       " mean: 0.79439, std: 0.03073, params: {'criterion': 'entropy', 'max_depth': 5},\n",
       " mean: 0.78131, std: 0.03509, params: {'criterion': 'entropy', 'max_depth': 6},\n",
       " mean: 0.76449, std: 0.03496, params: {'criterion': 'entropy', 'max_depth': 7},\n",
       " mean: 0.76822, std: 0.03457, params: {'criterion': 'entropy', 'max_depth': 8},\n",
       " mean: 0.75701, std: 0.03923, params: {'criterion': 'entropy', 'max_depth': 9},\n",
       " mean: 0.76636, std: 0.04278, params: {'criterion': 'entropy', 'max_depth': 10},\n",
       " mean: 0.75514, std: 0.03731, params: {'criterion': 'entropy', 'max_depth': 11},\n",
       " mean: 0.75888, std: 0.02557, params: {'criterion': 'entropy', 'max_depth': 12},\n",
       " mean: 0.76262, std: 0.05779, params: {'criterion': 'entropy', 'max_depth': 13},\n",
       " mean: 0.76075, std: 0.03008, params: {'criterion': 'entropy', 'max_depth': 14},\n",
       " mean: 0.76262, std: 0.03779, params: {'criterion': 'entropy', 'max_depth': 15},\n",
       " mean: 0.75701, std: 0.05647, params: {'criterion': 'entropy', 'max_depth': 16},\n",
       " mean: 0.75514, std: 0.04745, params: {'criterion': 'entropy', 'max_depth': 17},\n",
       " mean: 0.75888, std: 0.05031, params: {'criterion': 'entropy', 'max_depth': 18},\n",
       " mean: 0.77009, std: 0.02840, params: {'criterion': 'entropy', 'max_depth': 19},\n",
       " mean: 0.77196, std: 0.04488, params: {'criterion': 'entropy', 'max_depth': 20},\n",
       " mean: 0.76449, std: 0.04240, params: {'criterion': 'entropy', 'max_depth': 21},\n",
       " mean: 0.75701, std: 0.05436, params: {'criterion': 'entropy', 'max_depth': 22},\n",
       " mean: 0.75514, std: 0.04271, params: {'criterion': 'entropy', 'max_depth': 23},\n",
       " mean: 0.76075, std: 0.04530, params: {'criterion': 'entropy', 'max_depth': 24},\n",
       " mean: 0.75888, std: 0.04863, params: {'criterion': 'entropy', 'max_depth': 25},\n",
       " mean: 0.77196, std: 0.04862, params: {'criterion': 'entropy', 'max_depth': 26},\n",
       " mean: 0.75888, std: 0.03886, params: {'criterion': 'entropy', 'max_depth': 27},\n",
       " mean: 0.76449, std: 0.05645, params: {'criterion': 'entropy', 'max_depth': 28},\n",
       " mean: 0.76075, std: 0.04280, params: {'criterion': 'entropy', 'max_depth': 29},\n",
       " mean: 0.76262, std: 0.03567, params: {'criterion': 'entropy', 'max_depth': 30}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tree.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best Score:', 0.81495327102803738)\n",
      "('Best Combination:', {'criterion': 'entropy', 'max_depth': 3})\n",
      "('Best Estimator:', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'))\n"
     ]
    }
   ],
   "source": [
    "# 3 Looking for best estimator\n",
    "print (\"Best Score:\",grid_search_tree.best_score_)\n",
    "print (\"Best Combination:\",grid_search_tree.best_params_)\n",
    "print (\"Best Estimator:\",grid_search_tree.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_best = grid_search_tree.best_estimator_\n",
    "tree_best.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training error:', 0.17570093457943925)\n",
      "('Test error:', 0.22056074766355138)\n",
      "('Array of features:', array([ 0.02406062,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.02832349,  0.        ,  0.79940582,  0.        ,\n",
      "        0.03351326,  0.11469682,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ]))\n"
     ]
    }
   ],
   "source": [
    "print (\"Training error:\",1-tree_best.score(x_train,y_train))\n",
    "print (\"Test error:\",1-tree_best.score(x_test,y_test))\n",
    "print (\"Array of features:\",tree_best.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02406062,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.02832349,  0.        ,  0.79940582,  0.        ,\n",
       "        0.03351326,  0.11469682,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only 2 important features\n",
    "tree_best.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) What are the first 5 important features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Random Forest.**\n",
    "\n",
    "(1) Fit a random forest on the training set. Report the training error and test error.\n",
    "    \n",
    "(2) Use the function **grid_search.GridSearchCV** to find the best parameters. What's the best parameters? What's the best score? What's the training error and test error of the best model. The possible combination of the parameters may be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1- Using default Random forest parameters\n",
    "from sklearn import ensemble\n",
    "randomForest = ensemble.RandomForestClassifier()\n",
    "randomForest.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training error:', 0.035514018691588767)\n",
      "('Test error:', 0.22242990654205608)\n"
     ]
    }
   ],
   "source": [
    "print (\"Training error:\",1-randomForest.score(x_train,y_train))\n",
    "print (\"Test error:\",1-randomForest.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking for best combination\n",
    "grid_para_forest = {'criterion': ['gini', 'entropy'], 'max_depth': range(1, 31), \"n_estimators\": range(10, 110, 10)}\n",
    "grid_search_forest = gs.GridSearchCV(randomForest, grid_para_forest, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'criterion': ['gini', 'entropy'], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best Score:', 0.82056074766355136)\n",
      "('Best Combination:', {'n_estimators': 100, 'criterion': 'entropy', 'max_depth': 3})\n",
      "('Best Estimator:', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))\n"
     ]
    }
   ],
   "source": [
    "print (\"Best Score:\",grid_search_forest.best_score_)\n",
    "print (\"Best Combination:\",grid_search_forest.best_params_)\n",
    "print (\"Best Estimator:\",grid_search_forest.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_best = grid_search_forest.best_estimator_\n",
    "forest_best.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) What's the first 5 important features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training error:', 0.17009345794392527)\n",
      "('Test error:', 0.21121495327102802)\n",
      "[ 0.04548647  0.08462034  0.01706913  0.01713001  0.00828449  0.02752075\n",
      "  0.00182171  0.00643722  0.45331539  0.04469429  0.02692578  0.08411097\n",
      "  0.03510983  0.01848861  0.01495879  0.06862561  0.0454006 ]\n"
     ]
    }
   ],
   "source": [
    "print (\"Training error:\",1-forest_best.score(x_train,y_train))\n",
    "print (\"Test error:\",1-forest_best.score(x_test,y_test))\n",
    "print forest_best.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
